### A workflow to scrape ServiceTitan OpenAPI specs daily

name: Scrape OpenAPI Specs

on:
  schedule:
    # Run daily at 12 PM UTC
    - cron: '0 12 * * *'
  workflow_dispatch: # Allow manual triggers

env:
  FORCE_COLOR: "1"

jobs:
  scrape:
    name: Scrape ServiceTitan OpenAPI Specs
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write
    steps:
    - uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0

    - name: Set up Python
      uses: actions/setup-python@e797f83bcb11b83ae66e0230d6156d7c80228e7c # v6.0.0
      with:
        python-version: "3.13"

    - name: Set up uv
      uses: astral-sh/setup-uv@85856786d1ce8acfbcc2f13a5f3fbd6b938f9f41 # v7.1.2

    - name: Install Playwright browsers
      run: uv run playwright install chromium --with-deps

    - name: Run OpenAPI specs scraper
      run: uv run python scripts/scrape_openapi_specs.py

    - name: Check for changes
      continue-on-error: true
      id: git-check
      run: |
        git diff --exit-code tap_service_titan/openapi_specs/ || echo "changed=true" >> $GITHUB_OUTPUT

    - name: Open a Pull Request
      uses: peter-evans/create-pull-request@271a8d0340265f705b14b6d32b9829c1cb33d45e # v7.0.8
      if: steps.git-check.outputs.changed == 'true'
      with:
        title: 'fix: Update catalog from fresh OpenAPI specs'
