### A workflow to scrape ServiceTitan OpenAPI specs daily

name: Scrape OpenAPI Specs

on:
  schedule:
    # Run daily at 12 PM UTC
    - cron: '0 12 * * *'
  workflow_dispatch: # Allow manual triggers

env:
  FORCE_COLOR: "1"

jobs:
  scrape:
    name: Scrape ServiceTitan OpenAPI Specs
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write
    steps:
    - uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1

    - name: Set up Python
      uses: actions/setup-python@83679a892e2d95755f2dac6acb0bfd1e9ac5d548 # v6.1.0
      with:
        python-version: "3.13"

    - name: Set up uv
      uses: astral-sh/setup-uv@681c641aba71e4a1c380be3ab5e12ad51f415867 # v7.1.6

    - name: Install Playwright browsers
      run: uv run playwright install chromium --with-deps

    - name: Run OpenAPI specs scraper
      run: uv run python scripts/scrape_openapi_specs.py

    - name: Check for changes
      continue-on-error: true
      id: git-check
      run: |
        git diff --exit-code tap_service_titan/openapi_specs/ || echo "changed=true" >> $GITHUB_OUTPUT

    - name: Open a Pull Request
      uses: peter-evans/create-pull-request@22a9089034f40e5a961c8808d113e2c98fb63676 # v7.0.11
      if: steps.git-check.outputs.changed == 'true'
      with:
        title: 'fix: Update catalog from fresh OpenAPI specs'
